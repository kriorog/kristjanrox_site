{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5370906a",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"The Monty Hall Problem - Part 2\"\n",
    "subtitle: \"A mathematical approach to a solution\"\n",
    "author: \"Röx\"\n",
    "date: \"13 January 2026\"\n",
    "image: \"figures/a_beautiful_mind_2.jpg\"\n",
    "format: \n",
    "  live-html:\n",
    "    theme: journal\n",
    "    toc: true\n",
    "    toc-title: Contents\n",
    "    toc-depth: 3\n",
    "    smooth-scroll: true\n",
    "    number-sections: false\n",
    "    fig-caption: true\n",
    "engine: jupyter\n",
    "categories:\n",
    "  - probability theory\n",
    "  - monty hall\n",
    "  - Bayes' Law\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e57a8f",
   "metadata": {},
   "source": [
    "In [Part 1](../01_part_1/monty_hall.ipynb), the solution to the Monty Hall problem required a certain level of intuition to be accepted. The fact that the prior 2/3 probability of choosing the wrong door being fully transferred to the other door that Monty did not open may not be immediately obvious. Therefore, the reasoning provided is not complete.\n",
    "\n",
    "I prefer to let the mathematics - the language of logic and reason - yield a justified solution, without needing to accept a solution based on intuition. \n",
    "\n",
    "I will utilize the dependent nature of both Monty's choices and the choice the contestant has to make after being offered the choice of switching or staying. This dependency between variables indicates the probabilities being *conditional probabilities*, which are conditional on what information one has at the time of making a choice. For example, Monty chooses his door based on where the car is (which he knows) and what door the contestant chooses. Given this information, the probability that Monty will choose each door is not equal, and may be biased to one or more doors. Similarly, the contestant will have to make a choice on whether to switch based on his initially chosen door and the door that Monty opened.\n",
    "\n",
    "![*Oppie tells us to move ahead with the math.*](figures/oppenheimer_math.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed3385b",
   "metadata": {},
   "source": [
    "# Conditional probabilities\n",
    "Let's begin by defining some variables for our problem.\n",
    "\n",
    "Let $X$ describe the door hiding the car, $Y$ be the door chosen by the contestant, and $Z$ the door opened by Monty.\n",
    "\n",
    "Based on the structure and mechanics of the problem, one can see the following:\n",
    "\n",
    "- We assume no bias in the location of the car behind door $X$.\n",
    "\n",
    "- When Monty chooses his door $Z$ he knows the values of $X$ and $Y$. \n",
    "\n",
    "- The contestant initially chooses $Y$ at random, as he has no other information at that stage.\n",
    "\n",
    "- When offered the switch, the contestant strategy would be to choose the door with the highest probability of hiding the car - given the initially chosen $X$ and the door $Y$ opened by Monty. \n",
    "\n",
    "- In mathematical terms, the door $X$ with the highest conditional probability $P(X | Y, Z)$, which should be read as \"*the probability of $X$ given $Y$ and $Z$*\". This is a *conditional probability* as it is dependent on known values of $Y$ and $Z$.\n",
    "\n",
    "## How to interpret the conditional probabilities?\n",
    "Given the information in the problem, deducing the desired probability $P(X | Y, Z)$ by inspection is difficult. It is what we are trying to justify by intuition in [Part 1](../01_part_1/monty_hall.ipynb) on this problem as being 2/3 in favour of switching."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0364b5",
   "metadata": {},
   "source": [
    "# Inspection of each variable in the problem\n",
    "We can however see that the contestant chooses his initial door at random, i.e. each is equally likely to be chosen. Therefore we can reasonably assume the contestant choosing a door at random, i.e. $P(Y_j)=1/3$ for each door $j\\in\\{1,2,3\\}$.\n",
    "\n",
    "Also, the car's location is not dependent on anything. We can thus assume it being placed behind a door at random, i.e. $P(X_i)=1/3$ for each $i \\in \\{1,2,3\\}$.\n",
    "\n",
    "Therefore, the variables $X$ and $Y$ are independent random variables.\n",
    "\n",
    "However, Monty's chosen door $Z$ is dependent on $X$ and $Y$. Therefore, we can't model $P(Z_k)$ for each $k \\in \\{1,2,3\\}$ based on the structure and mechanics of the problem. However, we can model the conditional probability of what Monty does, given where the car is and what door the contestant initially chooses. Therefore, we can model $P(Z_k | X_i, Y_j)$ for various combinations $(i,j,k)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a31a764",
   "metadata": {},
   "source": [
    "# The key to the solution - Bayes' Law\n",
    "Note that none of the probabilities we could model based on the problem are the one we need, i.e. $P(X_i | Y_j, Z_k)$. However, we can relate this desired conditional probability with the one conditional probability we could model, i.e. $P(Z_k | X_i, Y_j)$ using Bayes' Law.\n",
    "\n",
    ":::{ .callout-important title=\"Bayes' Law\"}\n",
    "If $A$ and $B$ be different events and that $P(B) \\neq 0$, then\n",
    "\n",
    "$$\n",
    "P(A | B) = \\frac{P(B | A)P(A)}{P(B)},\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "- $P(A | B)$ is the conditional probability of event $A$ given that $B$ is true. This probability is also called the *posterior probability* of $A$ given $B$.\n",
    "\n",
    "- $P(B | A)$ is the conditional probability of event $B$ occuring given that $A$ is true. It is also called the *likelihood* of event $B$ given $A$ in the [Bayesian interpretation of probabilities](https://en.wikipedia.org/wiki/Bayesian_probability).\n",
    "\n",
    "- $P(A)$ and $P(B)$ are the probabilities of independently observing events $A$ and $B$. These are also known as *prior probabilities* of events $A$ and $B$ respectively.\n",
    ":::\n",
    "\n",
    "The premise of Bayesian probabilities is the notion that models of proabilities for a specific process or problem are in themselves predictions subject to likelihoods. Given certain observations, one aims to find the model with maximum likelihood of having produced the observed events.\n",
    "\n",
    "Bayes' Law can therefore be interpreted as relating the model's likelihood given observed events, to the probability of observing the events given the model.\n",
    "\n",
    "In our case, the *probability model* are the conditional probabilities $P(Z_k | X_i, Y_j)$ for all $(i,j,k)$ we deduced from the structure and mechanics of the problem, and would be analogous to $P(B | A)$ in the above definition of Bayes' Law. We should rather refer to $P(Z_k | X_i, Y_j)$ as being the *likelihood* of observing $Z_k$ given $X_i$ and $Y_j$.\n",
    "\n",
    "The posterior probability is the one we are interested in, i.e. $P(X_i | Y_j, Z_k)$ which would be analogous to $P(A | B)$ in Bayes' Law.\n",
    "\n",
    "Therefore, we can infer our desired conditional probability based on our likelihood model and the prior probabilities.\n",
    "\n",
    "## Bayes' Law applied to the problem\n",
    "Note that Bayes' Law considers one conditional event on each side of the equation. \n",
    "\n",
    "Therefore, for $P(Z_k | X_i, Y_j)$ to be analogous to the Bayes' $P(B | A)$, we need to interpret the conditional event as  being $B = (X_i, Y_j)$ i.e. the event of obtaining the values $X_i$ and $Y_j$ for each door pair $(i,j)$ in the same run of the game.\n",
    "\n",
    "However, we have established that $X_i$ and $Y_j$ are *independent* events for all pairs $(i,j)$. Therefore, the probability of $P(X_i, Y_j) = P(X_i)P(Y_j)$. We have the prior probabilities of both $X$ and $Y$ as being $P(X_i)=P(Y_j)=1/3$ for all $i$ and $j$.\n",
    "\n",
    "For our desired probability $P(X_i | Y_j, Z_k)$ we need the probability of the event $A = (Y_j, Z_k)$ i.e. the combined event of observing values $Y_j$ and $Z_k$ in each run of the game. These are dependent events. We know that Monty's choice $Z_k$ is dependent on both $X_i$ (where the car is) and $Y_j$ (door chosen by contestant) and we can model $P(Z_k | X_i, Y_j)$ based on that.\n",
    "\n",
    "With this, we can determine the required prior $P(Y_j, Z_k)$. First, using the [definition of conditional probability](https://en.wikipedia.org/wiki/Conditional_probability), we can write\n",
    "\n",
    "$$\n",
    "P(Y_j, Z_k) = P(Y_j \\cap Z_k) = P(Z_k | Y_j)P(Y_j).\n",
    "$$\n",
    "\n",
    "Then, using the [Total Law of Probability](https://en.wikipedia.org/wiki/Law_of_total_probability) on $P(Z_k | Y_j)$, we obtain for a given $j$ and $k$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    P(Y_j, Z_k) &= P(Z_k | Y_j)P(Y_j) \\\\\n",
    "                &= \\left( \\sum_{i \\in \\{1,2,3\\}} P(Z_k | X_i, Y_j)P(X_i) \\right) P(Y_j) \\\\\n",
    "                &= P(Y_j)\\sum_{i \\in \\{1,2,3\\}} P(Z_k | X_i, Y_j)P(X_i).\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "We have now demonstrated our ability to construct all of the required elements in Bayes' Law for its application to the Monty Hall problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4705f267",
   "metadata": {},
   "source": [
    "# Bayesian solution\n",
    "Bayes' Law in our case is\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    P(X_i | Y_j, Z_k)   &= \\frac{P(Z_k | X_i, Y_j)P(X_i, Y_j)}{P(Y_j, Z_j)} \\\\\n",
    "                        &= \\frac{P(Z_k | X_i, Y_j)P(X_i)P(Y_j)}{P(Y_j)\\sum_{i \\in \\{1,2,3\\}} P(Z_k | X_i, Y_j)P(X_i)}.\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "As the denominator $P(Y_j, Z_j)$ must be non-zero for the posterior to be defined - which it always is - as Monty always chooses a door.\n",
    "\n",
    "We also have the priors $P(X_i)=P(Y_j)=1/3$ for all $i$ and $j$. \n",
    "\n",
    "To construct our model of the likelihood $P(Z_k | X_i, Y_j)$ we need to re-visit Monty's behaviour in the game from [Part 1](../01_part_1/monty_hall.ipynb).\n",
    "\n",
    "- We know he never opens the door chosen by the contestant, i.e. $Z_k \\neq Y_i$ for all door pairs $(i,k)$. \n",
    "\n",
    "- We also know that Monty never opens the door with the car, i.e. $Z_k \\neq X_i$ for all door pairs $(i,k)$.\n",
    "\n",
    "- Since there are only three doors, the number of doors Monty can choose from for any given pair $(X_i, Y_j)$ are either one or two.\n",
    "\n",
    "- If the contestant initially chooses the correct door, i.e. $X_i = Y_j$, then Monty has two doors to choose from. Since both of these do not hide the car, we can assume he chooses at random. \n",
    "\n",
    "    Therefore, \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    P(Z_k | X_i, Y_j) = \n",
    "        \\begin{cases}\n",
    "            1/2     & \\text{ with } i=j, k \\notin \\{i,j\\}, \\\\\n",
    "            0       & \\text{ with } i=j, k \\in \\{i, j\\}.\n",
    "        \\end{cases}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "- If the contestant chooses a wrong door, i.e. which does not hide the car, then Monty has only one door to choose from. Since he must open a door, he will always choose the only remaining door. \n",
    "\n",
    "    Therefore, in this case\n",
    "$$\n",
    "\\begin{align}\n",
    "    P(Z_k | X_i, Y_j) = \n",
    "        \\begin{cases}\n",
    "            1   & \\text{ with } i \\neq j, k \\notin \\{i,j\\}, \\\\\n",
    "            0   & \\text{ with } i \\neq j, k \\in \\{i, j\\}.\n",
    "        \\end{cases}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Our problem now is evaluating the desired posterior $P(X_i | Y_j, Z_k)$ for all possible $(i,j,k)$. We have 3 options for each index, so there are $3^3 = 27$ possible combinations. Some of these will not be valid, some will.\n",
    "\n",
    "For this case it is better to write a short script to calculate all outcomes. We are interested in investigating posterior probability outcomes $P(X_i | Y_j, Z_k)$ where $i=j$, which is the probability of winning by not switching, and where $i \\neq j$ which is the probability of winning by switching.\n",
    "\n",
    "Please run the following code block by pressing **Run Code** to see the outcome. You can reset the code block by pressing **Start Over**. The calculation results will appear below the code block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07b79db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def calculate_full_monty_hall_details():\n",
    "    doors = [1, 2, 3]\n",
    "    combinations = []\n",
    "    \n",
    "    # Prior probabilities: P(Xi) and P(Yj) are both 1/3\n",
    "    p_x = 1/3\n",
    "    p_y = 1/3\n",
    "    \n",
    "    # Generate all 27 combinations (3 choices for X, Y, and Z)\n",
    "    for i in doors:  # Car door X\n",
    "        for j in doors:  # Contestant door Y\n",
    "            for k in doors:  # Monty door Z\n",
    "                # Likelihood P(Zk | Xi, Yj)\n",
    "                # Monty cannot open the car door (k == i) \n",
    "                # or the door the contestant chose (k == j)\n",
    "                if k == i or k == j:\n",
    "                    likelihood = 0\n",
    "                else:\n",
    "                    if i == j:\n",
    "                        likelihood = 0.5 # Two doors available\n",
    "                    else:\n",
    "                        likelihood = 1.0 # Only one door available\n",
    "                \n",
    "                # Joint Probability P(Xi, Yj, Zk) = Likelihood * P(Xi) * P(Yj)\n",
    "                joint = likelihood * p_x * p_y\n",
    "                \n",
    "                combinations.append({\n",
    "                    'Car_X': i,\n",
    "                    'Contestant_Y': j,\n",
    "                    'Monty_Z': k,\n",
    "                    'Likelihood': likelihood,\n",
    "                    'Joint': joint\n",
    "                })\n",
    "                \n",
    "    df = pd.DataFrame(combinations)\n",
    "    \n",
    "    # Calculate Evidence P(Yj, Zk) using the Law of Total Probability\n",
    "    evidence = df.groupby(['Contestant_Y', 'Monty_Z'])['Joint'].sum().reset_index()\n",
    "    evidence.columns = ['Contestant_Y', 'Monty_Z', 'Evidence']\n",
    "    \n",
    "    df = df.merge(evidence, on=['Contestant_Y', 'Monty_Z'])\n",
    "    \n",
    "    # Calculate Posterior P(Xi | Yj, Zk) = Joint / Evidence\n",
    "    df['Posterior'] = df.apply(lambda row: row['Joint'] / row['Evidence'] if row['Evidence'] > 0 else 0.0, axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "all_results = calculate_full_monty_hall_details()\n",
    "\n",
    "# Separate results into valid (Stay/Switch) and invalid\n",
    "stay_valid = all_results[(all_results['Car_X'] == all_results['Contestant_Y']) & (all_results['Likelihood'] > 0)]\n",
    "switch_valid = all_results[(all_results['Car_X'] != all_results['Contestant_Y']) & (all_results['Likelihood'] > 0)]\n",
    "invalid_results = all_results[all_results['Likelihood'] == 0]\n",
    "\n",
    "# Print all 27 combinations in grouped sections\n",
    "print(\"--- VALID OUTCOMES WHERE i = j (STAY) ---\")\n",
    "print(stay_valid[['Car_X', 'Contestant_Y', 'Monty_Z', 'Likelihood', 'Posterior']].to_string(index=False))\n",
    "\n",
    "print(\"\\n--- VALID OUTCOMES WHERE i != j (SWITCH) ---\")\n",
    "print(switch_valid[['Car_X', 'Contestant_Y', 'Monty_Z', 'Likelihood', 'Posterior']].to_string(index=False))\n",
    "\n",
    "print(\"\\n--- INVALID COMBINATIONS (LIKELIHOOD = 0) ---\")\n",
    "print(invalid_results[['Car_X', 'Contestant_Y', 'Monty_Z', 'Likelihood', 'Posterior']].to_string(index=False))\n",
    "\n",
    "# Verification of total counts\n",
    "print(f\"\\nTotal combinations printed: {len(stay_valid) + len(switch_valid) + len(invalid_results)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcbc8bd",
   "metadata": {},
   "source": [
    "The posterior is $P(X_i | Y_j, Z_k)$ - so we should interpret the case where $i=j$ as the *probability of the car being behind the door initially chosen by the contestant, given that Monty opened door $k$*. In other words, the probability of winning by staying with the chosen door.\n",
    " \n",
    "## Result for case $i=j$, i.e. contestant initially chose correct door\n",
    "In this case, the calculations show the posterior being $33.3\\%$, or\n",
    "\n",
    "$$\n",
    "P(X_i | Y_j, Z_k) = 1/3 \\hspace{0.5 cm} \\text{ if } i=j, \\text{ for all } k \\notin \\{i,j\\}.\n",
    "$$\n",
    "\n",
    "This means that the posterior probability of the car **not** being behind the chosen door is\n",
    "$$\n",
    "P(\\neg X_i | Y_j, Z_k) = 1- P(X_i | Y_j, Z_k) = 2/3 \\hspace{0.5 cm} \\text{ if } i=j, \\text{ for all } k \\notin \\{i, j\\}.\n",
    "$$\n",
    "\n",
    "Which means, we should switch to the other door.\n",
    "\n",
    "## Result for case $i \\neq j$, i.e. contestant initially chose wrong door\n",
    "For the other case, our posterior $P(X_i | Y_j, Z_k)$ for $i \\neq j$ is interpreted as *the probability of the car being behind door $i$ given that the contestant initially chose a different door $j$, and Monty openend door $k$*. In simpler terms, the probability of the car being behind the other remaining door. \n",
    "\n",
    "The calculations yield a probability of $66.7\\%$ of the car being behind the other door, i.e.\n",
    "\n",
    "$$\n",
    "P(X_i | Y_j, Z_k) = 2/3 \\hspace{0.5 cm} \\text{ if } i \\neq j, \\text{ for all } k \\notin \\{i,j\\}.\n",
    "$$\n",
    "\n",
    "By the same logic as above, for this case, the probability of winning by staying is\n",
    "$$\n",
    "P(\\neg X_i | Y_j, Z_k) = 1- P(X_i | Y_j, Z_k) = 1/3 \\hspace{0.5 cm} \\text{ if } i \\neq j, \\text{ for all } k \\notin \\{i, j\\}.\n",
    "$$\n",
    "\n",
    "So we should also switch to the other door.\n",
    "\n",
    "Therefore, we have shown, for all possible cases, the probability of winning being higher by switching to the other door. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381fd13c",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "The obtained result using the Bayesian approach to the problem yields the same result as was described in [Part 1](../01_part_1/monty_hall.ipynb) - which we also reinforced by simulation. What we have done differently in this solution - is to have the mathematics yield the outcome, without having to rely upon intuition or insight.\n",
    "\n",
    "The solution for the optimal strategy being to always switch doors does however not mean that it will guarantee a win in each trial - not at all. Instead, what this solution tells us, is that by following the strategy of switching doors, we can expect to win in 66.7\\% of the time, and lose in 33.3\\% of the time. We should observe this to be the outcome in repeated trials and approach these values as more and more trials are done. This is what we observed in the simulation in [Part 1](../01_part_1/monty_hall.ipynb).\n",
    "\n",
    "However, keep in mind, the above calculations are not a *simulation* of the problem, but exact mathematical calculations. The solution is therefore exact and complete, given our assumptions of the problem and our Bayesian interpretation of probabilities.\n",
    "\n",
    "There is something inherently beautiful in having mathematics, the language of reason and logic, yield us the solution without having any prior bias towards the outcome - although in this case we have an expectation towards the outcome, but none of that was part of the derivation of the above solution. \n",
    "\n",
    "Given the debates this problem has stirred in the past - based on its counterintuitive solution - a mathematical approach is indeed the only way to justify the outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c180a2",
   "metadata": {},
   "source": [
    "\\Röx"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "pyodide",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
